{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from scipy.special import expit\n",
    "import unittest\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def run_tests():\n",
    "  unittest.main(argv=[''], verbosity=1, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = OrderedDict(\n",
    "    amount_spent =  [50,  10, 20, 5,  95,  70,  100,  200, 0],\n",
    "    send_discount = [0,   1,  1,  1,  0,   0,   0,    0,   1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='amount_spent', y='send_discount', s=108, c=\"blue\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making decisions with Logistic regression  \n",
    "\n",
    "## Logistic regression model\n",
    "A closer look at the sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return expit(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSigmoid(unittest,TestCase):\n",
    "    def test_at_zero(self):\n",
    "        self.assertAlmostEqual(sigmoid(0), 0.5)\n",
    "    def test_at_negative(self):\n",
    "          self.assertAlmostEqual(sigmoid(-100), 0)\n",
    "        \n",
    "    def test_at_positive(self):\n",
    "      self.assertAlmostEqual(sigmoid(100), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10., 10., num=100)\n",
    "sig = sigmoid(x)\n",
    "\n",
    "plt.plot(x, sig, label=\"sigmoid\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend(prop={'size':16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can we find the parameters for our model  \n",
    "\n",
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(h, y):\n",
    "    return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLoss(unittest.TestCase):\n",
    "    def test_zero_h_zero_y(self):\n",
    "        self.assertLess(loss(h=0.000001, y=.000001), 0.0001)\n",
    "\n",
    "    def test_one_h_zero_y(self):\n",
    "        self.assertGreater(loss(h=0.9999, y=.000001), 9.0)\n",
    "\n",
    "    def test_zero_h_one_y(self):\n",
    "        self.assertGreater(loss(h=0.000001, y=0.9999), 9.0)\n",
    "\n",
    "    def test_one_h_one_y(self):\n",
    "        self.assertLess(loss(h=0.999999, y=0.999999), 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach #1 - Thinking of a number(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['amount_spent'].astype('float').values\n",
    "y = df['send_discount'].astype('float').values\n",
    "\n",
    "def predict(x, w):\n",
    "  return sigmoid(x * w)\n",
    "\n",
    "def print_result(y_hat, y):\n",
    "  print(f'loss: {np.round(loss(y_hat, y), 5)} predicted: {y_hat} actual: {y}')\n",
    "  \n",
    "y_hat = predict(x=X[0], w=.5)\n",
    "print_result(y_hat, y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach #2 - tryout a lot of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in np.arange(-1, 1, 0.1):\n",
    "    y_hat = predict(x=X[0], w=W)\n",
    "    print(loss(y_hat, y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach #3 - Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, n_iter=100000, lr=0.01):\n",
    "    w = np.zeros(X.shape[1])\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        z = np.dot(X, W)\n",
    "        h = sigmoid(z)\n",
    "        gradient = np.dot(X.T, (h - y)) / y.size\n",
    "        W -= lr * gradient\n",
    "\n",
    "        if(i % 10000 == 0):\n",
    "            e = loss(h, y)\n",
    "            print(f'loss: {e} \\t')\n",
    "            errors.append(e)\n",
    "\n",
    "    return W, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, errors = fit(X, y)\n",
    "plt.plot(np.arange(len(errors)), errors)\n",
    "plt.xlabel(\"iteration^10000\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, n_iter=100000, lr=0.001):\n",
    "\n",
    "    W = np.zeros(X.shape[1])\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        z = np.dot(X, W)\n",
    "        h = sigmoid(z)\n",
    "        gradient = np.dot(X.T, (h-y)) / y.size\n",
    "        W -= lr * gradient\n",
    "\n",
    "        if(i % 10000 == 0):\n",
    "            e = loss(h, y)\n",
    "            print(f'loss: {e} \\t')\n",
    "            errors.append(e)\n",
    "        \n",
    "    return W, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_intercept(X):\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    return np.concatenate((intercept, X), axis=1)\n",
    "\n",
    "def predict(X, W):\n",
    "    X = add_intercept(X)\n",
    "    return sigmoid(np.dot(X, W))\n",
    "\n",
    "def fit(X, y, n_iter=100000, lr=0.01):\n",
    "    X = add_intercept(X)\n",
    "    W = np.zeros(X.shape[1])\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    for i in range(n_iter):\n",
    "    z = np.dot(X, W)\n",
    "    h = sigmoid(z)\n",
    "    gradient = np.dot(X.T, (h - y)) / y.size\n",
    "    W -= lr * gradient\n",
    "\n",
    "    if(i % 10000 == 0):\n",
    "        e = loss(h, y)\n",
    "        errors.append(e)\n",
    "    \n",
    "return W, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, errors = fit(X, y)\n",
    "plt.plot(np.arange(len(errors)), errors)\n",
    "plt.xlabel(\"iteration^10000\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiding the complexity of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLogisticRegressor(unittest.TestCase):\n",
    "\n",
    "    def test_correct_prediction(self):\n",
    "        global X\n",
    "        global y\n",
    "        X = X.reshape(X.shape[0], 1)\n",
    "        clf = LogisticRegressor()\n",
    "        y_hat = clf.fit(X, y).predit(X)\n",
    "        self.assertTrue((y_hat == y).all())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
